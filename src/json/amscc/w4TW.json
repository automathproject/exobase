{
  "uuid": "w4TW",
  "titre": "Maximum de vraisemblance",
  "theme": [
    "maximum de vraisemblance",
    "variables aléatoires à densité"
  ],
  "niveau": "",
  "metadata": {
    "exo7id": "",
    "auteur": "",
    "createdAt": "2024-11-05",
    "hasIndication": false,
    "hasCorrection": true,
    "youtube": "",
    "chapitre": "",
    "sousChapitre": "",
    "organisation": "",
    "updatedAt": "2025-03-18T17:56:24.930Z"
  },
  "contenu": [
    {
      "id": "a6ee5949-f85c-43b9-a621-460ace2d6862",
      "type": "description",
      "value": {
        "latex": "On considère une variable aléatoire $X$ suivant une loi exponentielle de paramètre $\\theta > 0$. On rappelle que sa densité est donnée par :\n$$f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x} & \\text{ si } x \\geq 0 \\\\ 0 & \\text{ sinon. } \\end{cases}$$\nOn dispose d'un échantillon $(X_1,...,X_n)$ de $n$ variables aléatoires indépendantes et de même loi que $X$. On cherche à estimer le paramètre $\\theta$ par la méthode du maximum de vraisemblance.",
        "html": "<p>On considère une variable aléatoire <span\nclass=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de\nparamètre <span class=\"math inline\">\\(\\theta &gt; 0\\)</span>. On\nrappelle que sa densité est donnée par : <span\nclass=\"math display\">\\[f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x}\n&amp; \\text{ si } x \\geq 0 \\\\ 0 &amp; \\text{ sinon. }\n\\end{cases}\\]</span> On dispose d’un échantillon <span\nclass=\"math inline\">\\((X_1,...,X_n)\\)</span> de <span\nclass=\"math inline\">\\(n\\)</span> variables aléatoires indépendantes et\nde même loi que <span class=\"math inline\">\\(X\\)</span>. On cherche à\nestimer le paramètre <span class=\"math inline\">\\(\\theta\\)</span> par la\nméthode du maximum de vraisemblance.</p>\n"
      }
    },
    {
      "id": "57e4f92b-9f0b-42e5-93d0-72f9bbbc2f2c",
      "type": "question",
      "value": {
        "latex": "Écrire la vraisemblance $L(\\theta)$ de l'échantillon en fonction de $\\theta$ et des observations $(x_1,...,x_n)$.",
        "html": "<p>Écrire la vraisemblance <span\nclass=\"math inline\">\\(L(\\theta)\\)</span> de l’échantillon en fonction de\n<span class=\"math inline\">\\(\\theta\\)</span> et des observations <span\nclass=\"math inline\">\\((x_1,...,x_n)\\)</span>.</p>\n"
      }
    },
    {
      "id": "f950e3aa-83e4-496d-b1a4-2f7b393c8aa1",
      "type": "reponse",
      "value": {
        "latex": "Par indépendance des variables, la vraisemblance est le produit des densités :\n        $$\\begin{align*}\n            L(\\theta) &= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i \\geq 0} \\\\\n            &= \\theta^n e^{-\\theta \\sum_{i=1}^n x_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}$$",
        "html": "<p>Par indépendance des variables, la vraisemblance est le produit des\ndensités : <span class=\"math display\">\\[\\begin{align*}\n            L(\\theta) &amp;= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &amp;= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i\n\\geq 0} \\\\\n            &amp;= \\theta^n e^{-\\theta \\sum_{i=1}^n\nx_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "7326b4c3-bfb2-4639-b621-1e30c7890557",
      "type": "question",
      "value": {
        "latex": "En déduire la log-vraisemblance $\\ell(\\theta)$ puis calculer sa dérivée $\\ell'(\\theta)$.",
        "html": "<p>En déduire la log-vraisemblance <span\nclass=\"math inline\">\\(\\ell(\\theta)\\)</span> puis calculer sa dérivée\n<span class=\"math inline\">\\(\\ell&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "6c0dd270-4528-4105-844f-7e2543676a3b",
      "type": "reponse",
      "value": {
        "latex": "La log-vraisemblance est :\n        $$\\begin{align*}\n            \\ell(\\theta) &= \\ln(L(\\theta)) \\\\\n            &= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}$$\n        \n        Sa dérivée est :\n        $$\\ell'(\\theta) = \\frac{n}{\\theta} - \\sum_{i=1}^n x_i$$",
        "html": "<p>La log-vraisemblance est : <span\nclass=\"math display\">\\[\\begin{align*}\n            \\ell(\\theta) &amp;= \\ln(L(\\theta)) \\\\\n            &amp;= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}\\]</span></p>\n<p>Sa dérivée est : <span class=\"math display\">\\[\\ell&#39;(\\theta) =\n\\frac{n}{\\theta} - \\sum_{i=1}^n x_i\\]</span></p>\n"
      }
    },
    {
      "id": "fe509945-bdfc-4f8d-8b88-e663fcde4794",
      "type": "question",
      "value": {
        "latex": "En déduire  l'estimateur du maximum de vraisemblance $\\widehat{\\theta}_n$ de $\\theta$.",
        "html": "<p>En déduire l’estimateur du maximum de vraisemblance <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> de <span\nclass=\"math inline\">\\(\\theta\\)</span>.</p>\n"
      }
    },
    {
      "id": "3b869ad1-b700-48a7-9d9d-12279ed2e264",
      "type": "reponse",
      "value": {
        "latex": "L'équation $\\ell'(\\theta)=0$ donne :\n        $$\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &= 0 \\\\\n            \\frac{n}{\\theta} &= \\sum_{i=1}^n x_i \\\\\n            \\theta &= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}$$\n\n        Donc $\\widehat{\\theta}_n = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}$ où $\\overline{X_n}$ est la moyenne empirique.",
        "html": "<p>L’équation <span class=\"math inline\">\\(\\ell&#39;(\\theta)=0\\)</span>\ndonne : <span class=\"math display\">\\[\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &amp;= 0 \\\\\n            \\frac{n}{\\theta} &amp;= \\sum_{i=1}^n x_i \\\\\n            \\theta &amp;= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}\\]</span></p>\n<p>Donc <span class=\"math inline\">\\(\\widehat{\\theta}_n =\n\\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}\\)</span> où <span\nclass=\"math inline\">\\(\\overline{X_n}\\)</span> est la moyenne\nempirique.</p>\n"
      }
    },
    {
      "id": "826bdc3e-2f3c-4b0e-8bbc-163402932af3",
      "type": "question",
      "value": {
        "latex": "Vérifier que $\\widehat{\\theta}_n$ est bien un maximum en étudiant le signe de $\\ell''(\\theta)$.",
        "html": "<p>Vérifier que <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span>\nest bien un maximum en étudiant le signe de <span\nclass=\"math inline\">\\(\\ell&#39;&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "53402f82-e884-43d0-8dd8-5a233cf99c85",
      "type": "reponse",
      "value": {
        "latex": "On calcule la dérivée seconde :\n        $$\\ell''(\\theta) = -\\frac{n}{\\theta^2}$$\n        \n        Cette dérivée seconde est toujours négative pour $\\theta > 0$, donc $\\widehat{\\theta}_n$ correspond bien à un maximum.",
        "html": "<p>On calcule la dérivée seconde : <span\nclass=\"math display\">\\[\\ell&#39;&#39;(\\theta) =\n-\\frac{n}{\\theta^2}\\]</span></p>\n<p>Cette dérivée seconde est toujours négative pour <span\nclass=\"math inline\">\\(\\theta &gt; 0\\)</span>, donc <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> correspond bien à un\nmaximum.</p>\n"
      }
    },
    {
      "id": "5b2d8302-1300-428d-9fb3-5035aeb88e67",
      "type": "question",
      "value": {
        "latex": "Montrer que $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>Montrer que <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    },
    {
      "id": "80d12f63-bcd3-4770-8e90-ad68323622ac",
      "type": "reponse",
      "value": {
        "latex": "On a :\n        $$\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &= \\E\\left(\\overline{X_n}\\right) \\\\\n            &= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &= \\frac{1}{\\theta}\n        \\end{align*}$$\n        \n        Donc $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>On a : <span class=\"math display\">\\[\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &amp;=\n\\E\\left(\\overline{X_n}\\right) \\\\\n            &amp;= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &amp;= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &amp;= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &amp;= \\frac{1}{\\theta}\n        \\end{align*}\\]</span></p>\n<p>Donc <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    }
  ],
  "preview": "<p>On considère une variable aléatoire <span\nclass=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de\nparamètre <span class=\"math inline\"> ..."
}