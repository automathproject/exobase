{
  "uuid": "w4TW",
  "titre": "Maximum de vraisemblance",
  "theme": [
    "maximum de vraisemblance",
    "variables aléatoires à densité"
  ],
  "niveau": "",
  "metadata": {
    "exo7id": "",
    "auteur": "",
    "createdAt": "2024-11-05",
    "hasIndication": false,
    "hasCorrection": true,
    "youtube": "",
    "chapitre": "Probabilité continue",
    "sousChapitre": "Densité de probabilité",
    "organisation": "",
    "updatedAt": "2025-04-04T19:05:11.847Z",
    "resume": "L'exercice porte sur l'estimation du paramètre $\\theta$ d'une loi exponentielle par la méthode du maximum de vraisemblance, à partir d'un échantillon de $n$ variables aléatoires indépendantes et identiquement distribuées. Les compétences mises en œuvre sont : \n\n1.  Calcul de la vraisemblance $L(\\theta)$ et de la log-vraisemblance $\\ell(\\theta)$ de l'échantillon.\n2.  Calcul de la dérivée première $\\ell'(\\theta)$ de la log-vraisemblance.\n3.  Détermination de l'estimateur du maximum de vraisemblance $\\widehat{\\theta}_n$ en résolvant l'équation $\\ell'(\\theta) = 0$.\n4.  Vérification que $\\widehat{\\theta}_n$ est bien un maximum en étudiant le signe de la dérivée seconde $\\ell''(\\theta)$.\n5.  Démonstration du fait que $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$, en calculant son espérance.",
    "competences": [
      "calculer le maximum de vraisemblance d'un paramètre",
      "calculer la dérivée d'une fonction log-vraisemblance",
      "appliquer la définition de la vraisemblance pour un échantillon i.i.d.",
      "calculer l'espérance d'une variable aléatoire",
      "interpréter le signe de la dérivée seconde pour déterminer un maximum"
    ],
    "niveau_difficulte": "intermédiaire",
    "mots_cles": [
      "maximum de vraisemblance",
      "estimateur",
      "vraisemblance",
      "log-vraisemblance",
      "densité de probabilité",
      "loi exponentielle",
      "estimateur sans biais",
      "variables aléatoires i.i.d."
    ],
    "concepts_fondamentaux": [
      "maximum de vraisemblance",
      "densité de probabilité",
      "espérance mathématique",
      "indépendance de variables aléatoires"
    ],
    "prerequis": [
      "calcul différentiel (dérivées)",
      "fonctions logarithmes",
      "probabilités élémentaires",
      "variables aléatoires",
      "loi exponentielle (densité, espérance)"
    ],
    "type_exercice": "Problème à étapes",
    "temps_estime": "45-60 minutes"
  },
  "contenu": [
    {
      "id": "2a90775d-33aa-4a81-980a-122aba709aaa",
      "type": "description",
      "value": {
        "latex": "On considère une variable aléatoire $X$ suivant une loi exponentielle de paramètre $\\theta > 0$. On rappelle que sa densité est donnée par :\n$$f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x} & \\text{ si } x \\geq 0 \\\\ 0 & \\text{ sinon. } \\end{cases}$$\nOn dispose d'un échantillon $(X_1,...,X_n)$ de $n$ variables aléatoires indépendantes et de même loi que $X$. On cherche à estimer le paramètre $\\theta$ par la méthode du maximum de vraisemblance.",
        "html": "<p>On considère une variable aléatoire <span\nclass=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de\nparamètre <span class=\"math inline\">\\(\\theta &gt; 0\\)</span>. On\nrappelle que sa densité est donnée par : <span\nclass=\"math display\">\\[f_\\theta(x) = \\begin{cases} \\theta e^{-\\theta x}\n&amp; \\text{ si } x \\geq 0 \\\\ 0 &amp; \\text{ sinon. }\n\\end{cases}\\]</span> On dispose d’un échantillon <span\nclass=\"math inline\">\\((X_1,...,X_n)\\)</span> de <span\nclass=\"math inline\">\\(n\\)</span> variables aléatoires indépendantes et\nde même loi que <span class=\"math inline\">\\(X\\)</span>. On cherche à\nestimer le paramètre <span class=\"math inline\">\\(\\theta\\)</span> par la\nméthode du maximum de vraisemblance.</p>\n"
      }
    },
    {
      "id": "21b630b7-99b1-4d2f-9ab1-4db15bceab9b",
      "type": "question",
      "value": {
        "latex": "Écrire la vraisemblance $L(\\theta)$ de l'échantillon en fonction de $\\theta$ et des observations $(x_1,...,x_n)$.",
        "html": "<p>Écrire la vraisemblance <span\nclass=\"math inline\">\\(L(\\theta)\\)</span> de l’échantillon en fonction de\n<span class=\"math inline\">\\(\\theta\\)</span> et des observations <span\nclass=\"math inline\">\\((x_1,...,x_n)\\)</span>.</p>\n"
      }
    },
    {
      "id": "177025bf-96b8-4c1a-bb9d-0f64c3fbb890",
      "type": "reponse",
      "value": {
        "latex": "Par indépendance des variables, la vraisemblance est le produit des densités :\n        $$\\begin{align*}\n            L(\\theta) &= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i \\geq 0} \\\\\n            &= \\theta^n e^{-\\theta \\sum_{i=1}^n x_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}$$",
        "html": "<p>Par indépendance des variables, la vraisemblance est le produit des\ndensités : <span class=\"math display\">\\[\\begin{align*}\n            L(\\theta) &amp;= \\prod_{i=1}^n f_\\theta(x_i) \\\\\n            &amp;= \\prod_{i=1}^n \\theta e^{-\\theta x_i}\\mathbf{1}_{x_i\n\\geq 0} \\\\\n            &amp;= \\theta^n e^{-\\theta \\sum_{i=1}^n\nx_i}\\mathbf{1}_{\\min(x_i) \\geq 0}\n        \\end{align*}\\]</span></p>\n"
      }
    },
    {
      "id": "a1f0cf49-39ff-42cf-a809-17f77fafffcb",
      "type": "question",
      "value": {
        "latex": "En déduire la log-vraisemblance $\\ell(\\theta)$ puis calculer sa dérivée $\\ell'(\\theta)$.",
        "html": "<p>En déduire la log-vraisemblance <span\nclass=\"math inline\">\\(\\ell(\\theta)\\)</span> puis calculer sa dérivée\n<span class=\"math inline\">\\(\\ell&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "19269fcf-e1eb-449c-933c-470cd52dbf20",
      "type": "reponse",
      "value": {
        "latex": "La log-vraisemblance est :\n        $$\\begin{align*}\n            \\ell(\\theta) &= \\ln(L(\\theta)) \\\\\n            &= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}$$\n        \n        Sa dérivée est :\n        $$\\ell'(\\theta) = \\frac{n}{\\theta} - \\sum_{i=1}^n x_i$$",
        "html": "<p>La log-vraisemblance est : <span\nclass=\"math display\">\\[\\begin{align*}\n            \\ell(\\theta) &amp;= \\ln(L(\\theta)) \\\\\n            &amp;= n\\ln(\\theta) - \\theta \\sum_{i=1}^n x_i\n        \\end{align*}\\]</span></p>\n<p>Sa dérivée est : <span class=\"math display\">\\[\\ell&#39;(\\theta) =\n\\frac{n}{\\theta} - \\sum_{i=1}^n x_i\\]</span></p>\n"
      }
    },
    {
      "id": "b0fa9c59-35e7-4ea8-928e-99bc58fed69d",
      "type": "question",
      "value": {
        "latex": "En déduire  l'estimateur du maximum de vraisemblance $\\widehat{\\theta}_n$ de $\\theta$.",
        "html": "<p>En déduire l’estimateur du maximum de vraisemblance <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> de <span\nclass=\"math inline\">\\(\\theta\\)</span>.</p>\n"
      }
    },
    {
      "id": "fae6d654-b4a5-4805-93a2-3c32f3214e40",
      "type": "reponse",
      "value": {
        "latex": "L'équation $\\ell'(\\theta)=0$ donne :\n        $$\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &= 0 \\\\\n            \\frac{n}{\\theta} &= \\sum_{i=1}^n x_i \\\\\n            \\theta &= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}$$\n\n        Donc $\\widehat{\\theta}_n = \\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}$ où $\\overline{X_n}$ est la moyenne empirique.",
        "html": "<p>L’équation <span class=\"math inline\">\\(\\ell&#39;(\\theta)=0\\)</span>\ndonne : <span class=\"math display\">\\[\\begin{align*}\n            \\frac{n}{\\theta} - \\sum_{i=1}^n x_i &amp;= 0 \\\\\n            \\frac{n}{\\theta} &amp;= \\sum_{i=1}^n x_i \\\\\n            \\theta &amp;= \\frac{n}{\\sum_{i=1}^n x_i}\n        \\end{align*}\\]</span></p>\n<p>Donc <span class=\"math inline\">\\(\\widehat{\\theta}_n =\n\\frac{n}{\\sum_{i=1}^n x_i} = \\frac{1}{\\overline{X_n}}\\)</span> où <span\nclass=\"math inline\">\\(\\overline{X_n}\\)</span> est la moyenne\nempirique.</p>\n"
      }
    },
    {
      "id": "4bba131c-09b0-4d87-b8fa-aaca0ba090d2",
      "type": "question",
      "value": {
        "latex": "Vérifier que $\\widehat{\\theta}_n$ est bien un maximum en étudiant le signe de $\\ell''(\\theta)$.",
        "html": "<p>Vérifier que <span class=\"math inline\">\\(\\widehat{\\theta}_n\\)</span>\nest bien un maximum en étudiant le signe de <span\nclass=\"math inline\">\\(\\ell&#39;&#39;(\\theta)\\)</span>.</p>\n"
      }
    },
    {
      "id": "a501087d-3723-4091-b894-2dbc60ceef5f",
      "type": "reponse",
      "value": {
        "latex": "On calcule la dérivée seconde :\n        $$\\ell''(\\theta) = -\\frac{n}{\\theta^2}$$\n        \n        Cette dérivée seconde est toujours négative pour $\\theta > 0$, donc $\\widehat{\\theta}_n$ correspond bien à un maximum.",
        "html": "<p>On calcule la dérivée seconde : <span\nclass=\"math display\">\\[\\ell&#39;&#39;(\\theta) =\n-\\frac{n}{\\theta^2}\\]</span></p>\n<p>Cette dérivée seconde est toujours négative pour <span\nclass=\"math inline\">\\(\\theta &gt; 0\\)</span>, donc <span\nclass=\"math inline\">\\(\\widehat{\\theta}_n\\)</span> correspond bien à un\nmaximum.</p>\n"
      }
    },
    {
      "id": "19ff4238-ad8e-44ea-94f4-25cbad60c892",
      "type": "question",
      "value": {
        "latex": "Montrer que $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>Montrer que <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    },
    {
      "id": "48b755ad-b1b7-41b9-8ec0-5e3d44278c87",
      "type": "reponse",
      "value": {
        "latex": "On a :\n        $$\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &= \\E\\left(\\overline{X_n}\\right) \\\\\n            &= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &= \\frac{1}{\\theta}\n        \\end{align*}$$\n        \n        Donc $\\frac{1}{\\widehat{\\theta}_n}$ est un estimateur sans biais de $\\frac{1}{\\theta}$.",
        "html": "<p>On a : <span class=\"math display\">\\[\\begin{align*}\n            \\E\\left(\\frac{1}{\\widehat{\\theta}_n}\\right) &amp;=\n\\E\\left(\\overline{X_n}\\right) \\\\\n            &amp;= \\E\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) \\\\\n            &amp;= \\frac{1}{n}\\sum_{i=1}^n \\E(X_i) \\\\\n            &amp;= \\frac{1}{n} \\times n \\times \\frac{1}{\\theta} \\\\\n            &amp;= \\frac{1}{\\theta}\n        \\end{align*}\\]</span></p>\n<p>Donc <span\nclass=\"math inline\">\\(\\frac{1}{\\widehat{\\theta}_n}\\)</span> est un\nestimateur sans biais de <span\nclass=\"math inline\">\\(\\frac{1}{\\theta}\\)</span>.</p>\n"
      }
    }
  ],
  "preview": "<p>On considère une variable aléatoire <span\nclass=\"math inline\">\\(X\\)</span> suivant une loi exponentielle de\nparamètre <span class=\"math inline\"> ..."
}