{
  "uuid": "lX53",
  "titre": "Loi géométrique et estimation par maximum de vraisemblance",
  "theme": [
    "loi géométrique",
    "maximum de vraisemblance"
  ],
  "niveau": "",
  "metadata": {
    "exo7id": "",
    "auteur": "",
    "createdAt": "2022-09-24",
    "hasIndication": false,
    "hasCorrection": true,
    "youtube": "",
    "chapitre": "Probabilité discrète",
    "sousChapitre": "Lois de distributions",
    "organisation": "AMSCC",
    "updatedAt": "2025-04-04T19:03:28.347Z",
    "resume": "L'exercice porte sur l'estimation du paramètre $a$ d'une loi géométrique par la méthode du maximum de vraisemblance. Il s'agit de : \n1. Définir la fonction de vraisemblance $L(x_1,...,x_n, a) = \\prod_{k=1}^n \\frac{a^{x_k}}{(1+a)^{x_k+1}}$.\n2. Calculer la dérivée partielle de la fonction de vraisemblance par rapport à $a$ et trouver la valeur de $a$ qui maximise cette fonction.\n3. Déterminer l'estimateur de $a$, soit $T = \\frac{1}{n} \\sum_{k=0}^n X_k$.\n4. Calculer le biais de l'estimateur $T$, soit $B(T) = \\mathbb{E}(T-a)$, en utilisant l'espérance de la loi géométrique.",
    "competences": [
      "Appliquer la méthode / Calculer l'estimateur du maximum de vraisemblance",
      "Calculer l'espérance (mathématique) d'une variable aléatoire discrète",
      "dériver une fonction de vraisemblance",
      "Appliquer / Interpréter les propriétés des estimateurs (biais, convergence, efficacité)",
      "Appliquer / Calculer avec la loi géométrique"
    ],
    "niveau_difficulte": "intermédiaire",
    "mots_cles": [
      "loi géométrique",
      "maximum de vraisemblance",
      "estimation",
      "biais",
      "variable aléatoire discrète",
      "probabilité"
    ],
    "concepts_fondamentaux": [
      "loi géométrique",
      "fonction de vraisemblance",
      "estimateur du maximum de vraisemblance",
      "biais d'un estimateur",
      "espérance mathématique"
    ],
    "prerequis": [
      "probabilités de base",
      "variables aléatoires discrètes",
      "calcul différentiel (dérivées)",
      "notion d'estimateur"
    ],
    "type_exercice": "Exercice d'application directe",
    "temps_estime": "45 minutes"
  },
  "contenu": [
    {
      "id": "fda87198-069b-4792-a937-0b6ef1e391fa",
      "type": "description",
      "value": {
        "latex": "On fixe un réel $a>0$ et on définit une variable aléatoire $X$ sur $\\mathbb{N}$ dont la loi de probabilité est définie par \n\t$$\\PP(X=k)=\\frac{a^k}{(1+a)^{k+1}}$$\n\tpour tout $k \\in \\mathbb{N}$.",
        "html": "<p>On fixe un réel <span class=\"math inline\">\\(a&gt;0\\)</span> et on\ndéfinit une variable aléatoire <span class=\"math inline\">\\(X\\)</span>\nsur <span class=\"math inline\">\\(\\mathbb{N}\\)</span> dont la loi de\nprobabilité est définie par <span\nclass=\"math display\">\\[\\PP(X=k)=\\frac{a^k}{(1+a)^{k+1}}\\]</span> pour\ntout <span class=\"math inline\">\\(k \\in \\mathbb{N}\\)</span>.</p>\n"
      }
    },
    {
      "id": "19940167-0466-4433-995b-e0b0ce0125c9",
      "type": "question",
      "value": {
        "latex": "\\'A l'aide de la méthode du maximum de vraisemblance, définir un estimateur de $a$ et déterminer son biais.",
        "html": "<p>Á l’aide de la méthode du maximum de vraisemblance, définir un\nestimateur de <span class=\"math inline\">\\(a\\)</span> et déterminer son\nbiais.</p>\n"
      }
    },
    {
      "id": "9b1356e3-29df-43a2-a61d-e3fdd178bc33",
      "type": "reponse",
      "value": {
        "latex": "On définit un échantillon $X_1,...,X_n$ et on considère la probabilité que cet échantillon réalise un ensemble de valeurs $V=\\{x_1,...,x_n\\}$. La fonction de vraisemblance s'écrit alors \n\t$$L(x_1,...,x_n,a) = \\PP(X_1=x_1,...,X_n=x_n) = \\prod_{k=1}^{n} \\PP(X=x_k) = \\prod_{k=1}^n \\frac{a^{x_k}}{(1+a)^{x_k+1}} = \\frac{a^{\\sum x_k}}{(1+a)^{\\sum x_k+1}}$$\n\t\n\tOn dérive ce quotient par rapport à $a$, on factorise par $a^{\\sum x_k-1}(1+a)^{n+\\sum x_k -1}$ et on trouve que \n\t$$\\frac{\\partial L}{\\partial a}(x_1,...,x_n,a) = 0 \\iff \\sum_{k=0}^n x_k(1+a) - a(n+\\sum_{k=0}^n x_k) = 0 \\iff a = \\frac{1}{n} \\sum_{k=0}^n x_k$$\n\t\n\tOn a donc trouvé un meilleur estimateur du paramètre $a$ selon la méthode du maximum de vraisemblance : il s'agit de l'estimateur $T = \\frac{1}{n} \\sum_{k=0}^n X_k$.\n\t\n\tReste à calculer le biais de cet estimateur, autrement dit à calculer $B(T) = \\mathbb{E}(T-a)$. Or pour tout entier $i$, $X_i$ suit la loi définie ci-dessus et on espérance se calcule de la manière suivante :\n\t$$\\mathbb{E}(X_i) = \\sum_{k=0}^n k\\PP(X_i=k) = \\sum_{k=0}^n k \\left( \\frac{a}{1+a}  \\right)^{k-1} \\frac{a}{(1+a)^2} = \\frac{1}{\\left(1-\\frac{a}{1+a}\\right)^2} \\times \\frac{a}{(1+a)^2} = a$$\n\tDonc $B(T) = \\frac{1}{n} \\times n \\times a - a = 0$ : la variable $T$ est donc un estimateur sans biais du paramètre $a$.",
        "html": "<p>On définit un échantillon <span\nclass=\"math inline\">\\(X_1,...,X_n\\)</span> et on considère la\nprobabilité que cet échantillon réalise un ensemble de valeurs <span\nclass=\"math inline\">\\(V=\\{x_1,...,x_n\\}\\)</span>. La fonction de\nvraisemblance s’écrit alors <span\nclass=\"math display\">\\[L(x_1,...,x_n,a) = \\PP(X_1=x_1,...,X_n=x_n) =\n\\prod_{k=1}^{n} \\PP(X=x_k) = \\prod_{k=1}^n \\frac{a^{x_k}}{(1+a)^{x_k+1}}\n= \\frac{a^{\\sum x_k}}{(1+a)^{\\sum x_k+1}}\\]</span></p>\n<p>On dérive ce quotient par rapport à <span\nclass=\"math inline\">\\(a\\)</span>, on factorise par <span\nclass=\"math inline\">\\(a^{\\sum x_k-1}(1+a)^{n+\\sum x_k -1}\\)</span> et on\ntrouve que <span class=\"math display\">\\[\\frac{\\partial L}{\\partial\na}(x_1,...,x_n,a) = 0 \\iff \\sum_{k=0}^n x_k(1+a) - a(n+\\sum_{k=0}^n x_k)\n= 0 \\iff a = \\frac{1}{n} \\sum_{k=0}^n x_k\\]</span></p>\n<p>On a donc trouvé un meilleur estimateur du paramètre <span\nclass=\"math inline\">\\(a\\)</span> selon la méthode du maximum de\nvraisemblance : il s’agit de l’estimateur <span class=\"math inline\">\\(T\n= \\frac{1}{n} \\sum_{k=0}^n X_k\\)</span>.</p>\n<p>Reste à calculer le biais de cet estimateur, autrement dit à calculer\n<span class=\"math inline\">\\(B(T) = \\mathbb{E}(T-a)\\)</span>. Or pour\ntout entier <span class=\"math inline\">\\(i\\)</span>, <span\nclass=\"math inline\">\\(X_i\\)</span> suit la loi définie ci-dessus et on\nespérance se calcule de la manière suivante : <span\nclass=\"math display\">\\[\\mathbb{E}(X_i) = \\sum_{k=0}^n k\\PP(X_i=k) =\n\\sum_{k=0}^n k \\left( \\frac{a}{1+a}  \\right)^{k-1} \\frac{a}{(1+a)^2} =\n\\frac{1}{\\left(1-\\frac{a}{1+a}\\right)^2} \\times \\frac{a}{(1+a)^2} =\na\\]</span> Donc <span class=\"math inline\">\\(B(T) = \\frac{1}{n} \\times n\n\\times a - a = 0\\)</span> : la variable <span\nclass=\"math inline\">\\(T\\)</span> est donc un estimateur sans biais du\nparamètre <span class=\"math inline\">\\(a\\)</span>.</p>\n"
      }
    }
  ],
  "preview": "<p>On fixe un réel <span class=\"math inline\">\\(a&gt;0\\)</span> et on\ndéfinit une variable aléatoire <span class=\"math inline\">\\(X\\)</span>\nsur <span c ..."
}