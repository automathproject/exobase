{
  "resume": "Cet exercice porte sur la régression linéaire simple et l'optimisation du risque quadratique $R(a, b) = \\sum_{i=1}^n (y_i - (ax_i + b))^2$. Il vise à évaluer les compétences suivantes : \n\n1.  Développement et simplification d'expressions mathématiques pour exprimer $R(a,b)$ sous une forme polynomiale.\n2.  Calcul du gradient de $R(a, b)$, soit $\\nabla R(a,b)$.\n3.  Détermination du point critique $(a^*, b^*)$ en résolvant $\\nabla R(a^*, b^*) = 0$, ce qui implique la résolution d'un système d'équations linéaires.\n4.  Calcul de la matrice Hessienne de $R(a, b)$, soit $\\textrm{Hess}_R(a,b)$.\n5.  Démonstration de la convexité de la fonction $R$ en utilisant la Hessienne et l'inégalité de Cauchy-Schwarz.",
  "competences": [
    "calculer un gradient vectoriel",
    "calculer une matrice hessienne",
    "résoudre un système d'équations linéaires",
    "appliquer l'inégalité de Cauchy-Schwarz",
    "développer une expression polynomiale"
  ],
  "niveau_difficulte": "intermédiaire",
  "mots_cles": [
    "regression linéaire",
    "risque quadratique",
    "optimisation",
    "gradient",
    "hessienne",
    "point critique",
    "convexité",
    "Cauchy-Schwarz"
  ],
  "concepts_fondamentaux": [
    "optimisation de fonction à plusieurs variables",
    "calcul différentiel (gradient, hessienne)",
    "convexité",
    "systèmes d'équations linéaires"
  ],
  "prerequis": [
    "calcul différentiel de base (dérivées partielles)",
    "algèbre linéaire (systèmes d'équations, produit scalaire)",
    "notions de base sur l'optimisation"
  ],
  "type_exercice": "Problème à étapes",
  "temps_estime": "60-90 minutes"
}